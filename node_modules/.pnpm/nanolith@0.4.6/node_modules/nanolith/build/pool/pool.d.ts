import { ConcurrencyOption } from '../constants/pool.js';
import { PoolItem } from './pool_item.js';
/**
 * This is the big boy that manages all Nanolith workers ðŸ’ª
 */
declare class Pool {
    #private;
    /**
     * Easy access to the {@link ConcurrencyOption} enum right on `pool`.
     */
    readonly option: typeof ConcurrencyOption;
    /**
     * The maximum concurrency of the {@link Pool}, which defaults to one thread per core
     * on the machine being used. Can be changed with the `pool.setConcurrency` function
     */
    get maxConcurrency(): number;
    /**
     * Whether or not the pool has currently reached its max concurrency.
     */
    get maxed(): boolean;
    /**
     * The current number of item in the pool's queue on the current thread.
     */
    get queueLength(): number;
    /**
     * The current number of workers that are running under the pool.
     */
    get activeCount(): number;
    /**
     * A `boolean` indicating whether or not the pool is currently doing nothing.
     */
    get idle(): boolean;
    /**
     * Returns the internal `PoolItemOptions` for the next worker in the queue to be run.
     */
    get next(): import("../types/pool.js").PoolItemOptions;
    /**
     * @param option A {@link ConcurrencyOption}
     *
     * Modify the `maxConcurrency` of the pool. Use this wisely.
     * The {@link ConcurrencyOption} value defines how many workers `Pool` will allow to
     * run at the same time. It defaults to one worker per core on
     * the machine running the process.
     */
    setConcurrency<Option extends ConcurrencyOption>(option: Option): void;
    /**
     * ðŸ’¥ **HEY!** ðŸ’¥
     *
     * Don't use this unless you really know what you're doing.
     * This method is used internally to queue tasks and services up to the pool
     * to be created and run.
     */
    __enqueue(item: PoolItem): void;
}
/**
 * The single cross-thread global instance of {@link Pool} that manages all Nanolith workers ðŸ’ª
 */
export declare const pool: Pool;
export {};
